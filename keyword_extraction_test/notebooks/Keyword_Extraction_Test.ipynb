{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import networkx as nx\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/choiwonjun-macbook/nltk_data', '/Users/choiwonjun-macbook/.local/share/virtualenvs/keyword_extraction_test-fUJ8m5h5/nltk_data', '/Users/choiwonjun-macbook/.local/share/virtualenvs/keyword_extraction_test-fUJ8m5h5/share/nltk_data', '/Users/choiwonjun-macbook/.local/share/virtualenvs/keyword_extraction_test-fUJ8m5h5/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ í˜„ì¬ ì‘ì—… í´ë”: /Users/choiwonjun-macbook/nebula/nebula-ai-research/keyword_extraction_test/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "source": [
    "# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ (TextRankì—ì„œ í•„ìš”)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "# ë¶„ì„í•  í´ë” ê²½ë¡œ ì„¤ì •\n",
    "TEXT_FOLDER = \"../../data/processed_text\"  # í´ë” ê²½ë¡œ ìˆ˜ì •\n",
    "\n",
    "print(\"ğŸ“‚ í˜„ì¬ ì‘ì—… í´ë”:\", os.getcwd())\n",
    "# ë°ì´í„° ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_tfidf(text, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "    scores = tfidf_matrix.toarray()[0]\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    keyword_scores = sorted(zip(words, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in keyword_scores[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TextRank ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "def extract_keywords_textrank(text, top_n=5):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "    word_graph = nx.Graph()\n",
    "    for w1, w2 in combinations(set(words), 2):\n",
    "        word_graph.add_edge(w1, w2)\n",
    "\n",
    "    scores = nx.pagerank(word_graph)\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in sorted_words[:top_n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "def extract_keywords_lda(text, num_topics=1, top_n=5):\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "    term_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda_model.fit(term_matrix)\n",
    "\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    topics = lda_model.components_\n",
    "\n",
    "    topic_keywords = [words[i] for i in topics[0].argsort()[-top_n:]]\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_bert(text, top_n=5):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "    token_weights = outputs.last_hidden_state.mean(dim=2).squeeze().detach().numpy()\n",
    "\n",
    "    keyword_scores = sorted(zip(tokens, token_weights), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in keyword_scores[:top_n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7383fd5338e45bfaa336ad5e5943fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d709aaadeb34ab0990975ceeab14015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6c1e43fc2414184097ae0bfbd8505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b4d071396b4c678b603573be818a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691c557372a74dab93ef567baddc632e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ğŸ“‚ í´ë” ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ë° ì•Œê³ ë¦¬ì¦˜ ì ìš©\n",
    "for filename in os.listdir(TEXT_FOLDER):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(TEXT_FOLDER, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # ê° ì•Œê³ ë¦¬ì¦˜ ì ìš©\n",
    "        tfidf_keywords = extract_keywords_tfidf(text)\n",
    "        # textrank_keywords = extract_keywords_textrank(text)\n",
    "        lda_keywords = extract_keywords_lda(text)\n",
    "        bert_keywords = extract_keywords_bert(text)\n",
    "\n",
    "        # ğŸ“Œ ê²°ê³¼ DataFrameì— ì¶”ê°€\n",
    "        data.append({\n",
    "            \"íŒŒì¼ëª…\": filename,\n",
    "            \"TF-IDF\": \", \".join(tfidf_keywords),\n",
    "            # \"TextRank\": \", \".join(textrank_keywords),\n",
    "            \"LDA\": \", \".join(lda_keywords),\n",
    "            \"BERT\": \", \".join(bert_keywords),\n",
    "        })\n",
    "\n",
    "# ğŸ“Š DataFrame ìƒì„± ë° ê²°ê³¼ í™•ì¸\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>íŒŒì¼ëª…</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_18.txt</td>\n",
       "      <td>ë‹µê¸€, 1ê°œì˜, ê·¸ë ‡ê¸°ì—, ì‘ì›í•©ë‹ˆë‹¤, ë‚˜ëŠ”</td>\n",
       "      <td>ë‚˜ëŠ”, ì‘ì›í•©ë‹ˆë‹¤, ê·¸ë ‡ê¸°ì—, 1ê°œì˜, ë‹µê¸€</td>\n",
       "      <td>squeeze, squeeze, [CLS], 1, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_19.txt</td>\n",
       "      <td>fiber, flatmap, value, const, maybe</td>\n",
       "      <td>maybe, const, value, flatmap, fiber</td>\n",
       "      <td>[CLS], react, 8, 3, ran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_20.txt</td>\n",
       "      <td>ai, ìµœì‹ , ìˆìŠµë‹ˆë‹¤, aiê°€, ê¸°ìˆ </td>\n",
       "      <td>ëª¨ë¸, aiê°€, ìˆìŠµë‹ˆë‹¤, ìµœì‹ , ai</td>\n",
       "      <td>gemini, claude, ##ai, ##2, [CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_9.txt</td>\n",
       "      <td>ìƒíƒœ, const, ì—…ë°ì´íŠ¸, null, update</td>\n",
       "      <td>update, null, ì—…ë°ì´íŠ¸, const, ìƒíƒœ</td>\n",
       "      <td>react, [CLS], 19, 19, ##tate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_8.txt</td>\n",
       "      <td>line, wscellrowi, ì—‘ì…€, credit, import</td>\n",
       "      <td>import, subject_name, ì—‘ì…€, wscellrowi, line</td>\n",
       "      <td>[CLS], ##com, files, files, https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blog_5.txt</td>\n",
       "      <td>í•­í•´, ìˆìŠµë‹ˆë‹¤, ì´ëŸ°, í”„ë¡ íŠ¸ì—”ë“œ, í”ŒëŸ¬ìŠ¤</td>\n",
       "      <td>í”„ë¡ íŠ¸ì—”ë“œ, í”ŒëŸ¬ìŠ¤, ì´ëŸ°, ìˆìŠµë‹ˆë‹¤, í•­í•´</td>\n",
       "      <td>[CLS], 3, 3, ##á„€, 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blog_4.txt</td>\n",
       "      <td>ì´ë¯¸ì§€, js, ê±°ì•¼, ì‰½ê²Œ, ì´ì•¼ê¸°</td>\n",
       "      <td>ì‰½ê²Œ, ê±°ì•¼, ì´ì•¼ê¸°, js, ì´ë¯¸ì§€</td>\n",
       "      <td>##loading, [CLS], lazy, 3, 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blog_6.txt</td>\n",
       "      <td>typescript, ë„¤ì´í‹°ë¸Œ, ëª¨ë“ , ê²ƒì…ë‹ˆë‹¤, typescriptì˜</td>\n",
       "      <td>í˜„ì¬, ê²ƒì…ë‹ˆë‹¤, ëª¨ë“ , ë„¤ì´í‹°ë¸Œ, typescript</td>\n",
       "      <td>faster, 16, [CLS], ##us, ##us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>blog_7.txt</td>\n",
       "      <td>ìŠ¤ì¼ˆë ˆí†¤, ë¡œë”©, div, uië¥¼, classname</td>\n",
       "      <td>classname, div, uië¥¼, ë¡œë”©, ìŠ¤ì¼ˆë ˆí†¤</td>\n",
       "      <td>[CLS], 6, 33, 5, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog_3.txt</td>\n",
       "      <td>ê²ƒì´, ì–´ë–»ê²Œ, ê¸°ìˆ , ê¸°ì—…, ë‚´ê°€</td>\n",
       "      <td>í•˜ëŠ”, ê¸°ì—…, ê¸°ìˆ , ì–´ë–»ê²Œ, ê²ƒì´</td>\n",
       "      <td>[CLS], golden, golden, 7, ##dus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blog_2.txt</td>\n",
       "      <td>user, const, error, userid, data</td>\n",
       "      <td>div, userid, error, const, user</td>\n",
       "      <td>##ssing, ##cek, 41, ##sibility, [CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>blog_1.txt</td>\n",
       "      <td>llmì´, ìˆì–´ìš”, function, openai, llm</td>\n",
       "      <td>llm, openai, function, ìˆì–´ìš”, llmì´</td>\n",
       "      <td>agent, ##ai, [CLS], open, ##ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>blog_11.txt</td>\n",
       "      <td>ì •ë§, ìˆìŠµë‹ˆë‹¤, ã…ã…, 3ì›”, ê·¸ë¦¬ê³ </td>\n",
       "      <td>3ì›”, ì—°êµ¬, ã…ã…, ìˆìŠµë‹ˆë‹¤, ì •ë§</td>\n",
       "      <td>offer, associate, offer, [CLS], letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blog_10.txt</td>\n",
       "      <td>ë‚´í•œ, ê³µì—°, showpot, í‹°ì¼“íŒ…, ì •ë³´ë¥¼</td>\n",
       "      <td>ì •ë³´ë¥¼, í‹°ì¼“íŒ…, showpot, ê³µì—°, ë‚´í•œ</td>\n",
       "      <td>it, [CLS], ##pp, 15, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blog_12.txt</td>\n",
       "      <td>í”„ë¡œì íŠ¸, ìŠ¤ëª°ë¹…ì›¨ë”©, ì˜¤í”ˆ, ì´ë²ˆ, í•¨ê»˜</td>\n",
       "      <td>ì´ë²ˆ, ìŠ¤ëª°ë¹…ì›¨ë”©, ì˜¤í”ˆ, í•¨ê»˜, í”„ë¡œì íŠ¸</td>\n",
       "      <td>[CLS], ##z, react, api, fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>blog_13.txt</td>\n",
       "      <td>const, console, log, ìˆë‹¤, í•¨ìˆ˜í˜•</td>\n",
       "      <td>í•¨ìˆ˜í˜•, ìˆë‹¤, console, log, const</td>\n",
       "      <td>cs, [CLS], lee, 6, 58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>blog_17.txt</td>\n",
       "      <td>ë¬¸ì„œ, mdxprovider, ì»´í¬ë„ŒíŠ¸ë¥¼, components, mdx</td>\n",
       "      <td>mdx, ê²ƒì´ë‹¤, mdxprovider, ì»´í¬ë„ŒíŠ¸ë¥¼, ë¬¸ì„œ</td>\n",
       "      <td>[CLS], ##ct, react, 10, ##x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>blog_16.txt</td>\n",
       "      <td>text, ëŒ€í•œ, ìˆëŠ”, openai, ìˆìŠµë‹ˆë‹¤</td>\n",
       "      <td>ìˆìŠµë‹ˆë‹¤, openai, ìˆëŠ”, text, ëŒ€í•œ</td>\n",
       "      <td>[CLS], agent, calling, ##c, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>blog_14.txt</td>\n",
       "      <td>ìì‹, ìˆìŠµë‹ˆë‹¤, const, spawn, data</td>\n",
       "      <td>data, spawn, const, ìˆìŠµë‹ˆë‹¤, ìì‹</td>\n",
       "      <td>spawn, 31, ##ode, sonny, [CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>blog_15.txt</td>\n",
       "      <td>func, agent, ìˆì–´ìš”, typia, function</td>\n",
       "      <td>ì§ì ‘, typia, agent, ìˆì–´ìš”, func</td>\n",
       "      <td>##sons, claude, signature, ##sons, ##sons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            íŒŒì¼ëª…                                   TF-IDF  \\\n",
       "0   blog_18.txt                 ë‹µê¸€, 1ê°œì˜, ê·¸ë ‡ê¸°ì—, ì‘ì›í•©ë‹ˆë‹¤, ë‚˜ëŠ”   \n",
       "1   blog_19.txt      fiber, flatmap, value, const, maybe   \n",
       "2   blog_20.txt                    ai, ìµœì‹ , ìˆìŠµë‹ˆë‹¤, aiê°€, ê¸°ìˆ    \n",
       "3    blog_9.txt            ìƒíƒœ, const, ì—…ë°ì´íŠ¸, null, update   \n",
       "4    blog_8.txt     line, wscellrowi, ì—‘ì…€, credit, import   \n",
       "5    blog_5.txt                 í•­í•´, ìˆìŠµë‹ˆë‹¤, ì´ëŸ°, í”„ë¡ íŠ¸ì—”ë“œ, í”ŒëŸ¬ìŠ¤   \n",
       "6    blog_4.txt                     ì´ë¯¸ì§€, js, ê±°ì•¼, ì‰½ê²Œ, ì´ì•¼ê¸°   \n",
       "7    blog_6.txt  typescript, ë„¤ì´í‹°ë¸Œ, ëª¨ë“ , ê²ƒì…ë‹ˆë‹¤, typescriptì˜   \n",
       "8    blog_7.txt            ìŠ¤ì¼ˆë ˆí†¤, ë¡œë”©, div, uië¥¼, classname   \n",
       "9    blog_3.txt                      ê²ƒì´, ì–´ë–»ê²Œ, ê¸°ìˆ , ê¸°ì—…, ë‚´ê°€   \n",
       "10   blog_2.txt         user, const, error, userid, data   \n",
       "11   blog_1.txt         llmì´, ìˆì–´ìš”, function, openai, llm   \n",
       "12  blog_11.txt                    ì •ë§, ìˆìŠµë‹ˆë‹¤, ã…ã…, 3ì›”, ê·¸ë¦¬ê³    \n",
       "13  blog_10.txt                ë‚´í•œ, ê³µì—°, showpot, í‹°ì¼“íŒ…, ì •ë³´ë¥¼   \n",
       "14  blog_12.txt                  í”„ë¡œì íŠ¸, ìŠ¤ëª°ë¹…ì›¨ë”©, ì˜¤í”ˆ, ì´ë²ˆ, í•¨ê»˜   \n",
       "15  blog_13.txt             const, console, log, ìˆë‹¤, í•¨ìˆ˜í˜•   \n",
       "16  blog_17.txt  ë¬¸ì„œ, mdxprovider, ì»´í¬ë„ŒíŠ¸ë¥¼, components, mdx   \n",
       "17  blog_16.txt               text, ëŒ€í•œ, ìˆëŠ”, openai, ìˆìŠµë‹ˆë‹¤   \n",
       "18  blog_14.txt             ìì‹, ìˆìŠµë‹ˆë‹¤, const, spawn, data   \n",
       "19  blog_15.txt        func, agent, ìˆì–´ìš”, typia, function   \n",
       "\n",
       "                                           LDA  \\\n",
       "0                     ë‚˜ëŠ”, ì‘ì›í•©ë‹ˆë‹¤, ê·¸ë ‡ê¸°ì—, 1ê°œì˜, ë‹µê¸€   \n",
       "1          maybe, const, value, flatmap, fiber   \n",
       "2                        ëª¨ë¸, aiê°€, ìˆìŠµë‹ˆë‹¤, ìµœì‹ , ai   \n",
       "3                update, null, ì—…ë°ì´íŠ¸, const, ìƒíƒœ   \n",
       "4   import, subject_name, ì—‘ì…€, wscellrowi, line   \n",
       "5                     í”„ë¡ íŠ¸ì—”ë“œ, í”ŒëŸ¬ìŠ¤, ì´ëŸ°, ìˆìŠµë‹ˆë‹¤, í•­í•´   \n",
       "6                         ì‰½ê²Œ, ê±°ì•¼, ì´ì•¼ê¸°, js, ì´ë¯¸ì§€   \n",
       "7               í˜„ì¬, ê²ƒì…ë‹ˆë‹¤, ëª¨ë“ , ë„¤ì´í‹°ë¸Œ, typescript   \n",
       "8                classname, div, uië¥¼, ë¡œë”©, ìŠ¤ì¼ˆë ˆí†¤   \n",
       "9                          í•˜ëŠ”, ê¸°ì—…, ê¸°ìˆ , ì–´ë–»ê²Œ, ê²ƒì´   \n",
       "10             div, userid, error, const, user   \n",
       "11            llm, openai, function, ìˆì–´ìš”, llmì´   \n",
       "12                        3ì›”, ì—°êµ¬, ã…ã…, ìˆìŠµë‹ˆë‹¤, ì •ë§   \n",
       "13                   ì •ë³´ë¥¼, í‹°ì¼“íŒ…, showpot, ê³µì—°, ë‚´í•œ   \n",
       "14                     ì´ë²ˆ, ìŠ¤ëª°ë¹…ì›¨ë”©, ì˜¤í”ˆ, í•¨ê»˜, í”„ë¡œì íŠ¸   \n",
       "15                í•¨ìˆ˜í˜•, ìˆë‹¤, console, log, const   \n",
       "16            mdx, ê²ƒì´ë‹¤, mdxprovider, ì»´í¬ë„ŒíŠ¸ë¥¼, ë¬¸ì„œ   \n",
       "17                  ìˆìŠµë‹ˆë‹¤, openai, ìˆëŠ”, text, ëŒ€í•œ   \n",
       "18                data, spawn, const, ìˆìŠµë‹ˆë‹¤, ìì‹   \n",
       "19                 ì§ì ‘, typia, agent, ìˆì–´ìš”, func   \n",
       "\n",
       "                                         BERT  \n",
       "0               squeeze, squeeze, [CLS], 1, 3  \n",
       "1                     [CLS], react, 8, 3, ran  \n",
       "2            gemini, claude, ##ai, ##2, [CLS]  \n",
       "3                react, [CLS], 19, 19, ##tate  \n",
       "4           [CLS], ##com, files, files, https  \n",
       "5                        [CLS], 3, 3, ##á„€, 10  \n",
       "6                ##loading, [CLS], lazy, 3, 8  \n",
       "7               faster, 16, [CLS], ##us, ##us  \n",
       "8                          [CLS], 6, 33, 5, 3  \n",
       "9             [CLS], golden, golden, 7, ##dus  \n",
       "10      ##ssing, ##cek, 41, ##sibility, [CLS]  \n",
       "11             agent, ##ai, [CLS], open, ##ge  \n",
       "12     offer, associate, offer, [CLS], letter  \n",
       "13                     it, [CLS], ##pp, 15, 3  \n",
       "14                 [CLS], ##z, react, api, fe  \n",
       "15                      cs, [CLS], lee, 6, 58  \n",
       "16                [CLS], ##ct, react, 10, ##x  \n",
       "17              [CLS], agent, calling, ##c, 3  \n",
       "18             spawn, 31, ##ode, sonny, [CLS]  \n",
       "19  ##sons, claude, signature, ##sons, ##sons  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keyword_extraction_test-fUJ8m5h5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
