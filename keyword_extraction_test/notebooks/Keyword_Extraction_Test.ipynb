{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import networkx as nx\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/choiwonjun-macbook/nltk_data', '/Users/choiwonjun-macbook/.local/share/virtualenvs/keyword_extraction_test-fUJ8m5h5/nltk_data', '/Users/choiwonjun-macbook/.local/share/virtualenvs/keyword_extraction_test-fUJ8m5h5/share/nltk_data', '/Users/choiwonjun-macbook/.local/share/virtualenvs/keyword_extraction_test-fUJ8m5h5/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 현재 작업 폴더: /Users/choiwonjun-macbook/nebula/nebula-ai-research/keyword_extraction_test/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "source": [
    "# NLTK 데이터 다운로드 (TextRank에서 필요)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "# 분석할 폴더 경로 설정\n",
    "TEXT_FOLDER = \"../../data/processed_text\"  # 폴더 경로 수정\n",
    "\n",
    "print(\"📂 현재 작업 폴더:\", os.getcwd())\n",
    "# 데이터 저장용 리스트\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_tfidf(text, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "    scores = tfidf_matrix.toarray()[0]\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    keyword_scores = sorted(zip(words, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in keyword_scores[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TextRank 기반 키워드 추출\n",
    "def extract_keywords_textrank(text, top_n=5):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "    word_graph = nx.Graph()\n",
    "    for w1, w2 in combinations(set(words), 2):\n",
    "        word_graph.add_edge(w1, w2)\n",
    "\n",
    "    scores = nx.pagerank(word_graph)\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in sorted_words[:top_n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA 기반 키워드 추출\n",
    "def extract_keywords_lda(text, num_topics=1, top_n=5):\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "    term_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda_model.fit(term_matrix)\n",
    "\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    topics = lda_model.components_\n",
    "\n",
    "    topic_keywords = [words[i] for i in topics[0].argsort()[-top_n:]]\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_bert(text, top_n=5):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "    token_weights = outputs.last_hidden_state.mean(dim=2).squeeze().detach().numpy()\n",
    "\n",
    "    keyword_scores = sorted(zip(tokens, token_weights), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in keyword_scores[:top_n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7383fd5338e45bfaa336ad5e5943fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d709aaadeb34ab0990975ceeab14015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6c1e43fc2414184097ae0bfbd8505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b4d071396b4c678b603573be818a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691c557372a74dab93ef567baddc632e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📂 폴더 내 모든 텍스트 파일 읽기 및 알고리즘 적용\n",
    "for filename in os.listdir(TEXT_FOLDER):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(TEXT_FOLDER, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # 각 알고리즘 적용\n",
    "        tfidf_keywords = extract_keywords_tfidf(text)\n",
    "        # textrank_keywords = extract_keywords_textrank(text)\n",
    "        lda_keywords = extract_keywords_lda(text)\n",
    "        bert_keywords = extract_keywords_bert(text)\n",
    "\n",
    "        # 📌 결과 DataFrame에 추가\n",
    "        data.append({\n",
    "            \"파일명\": filename,\n",
    "            \"TF-IDF\": \", \".join(tfidf_keywords),\n",
    "            # \"TextRank\": \", \".join(textrank_keywords),\n",
    "            \"LDA\": \", \".join(lda_keywords),\n",
    "            \"BERT\": \", \".join(bert_keywords),\n",
    "        })\n",
    "\n",
    "# 📊 DataFrame 생성 및 결과 확인\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>파일명</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>LDA</th>\n",
       "      <th>BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog_18.txt</td>\n",
       "      <td>답글, 1개의, 그렇기에, 응원합니다, 나는</td>\n",
       "      <td>나는, 응원합니다, 그렇기에, 1개의, 답글</td>\n",
       "      <td>squeeze, squeeze, [CLS], 1, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog_19.txt</td>\n",
       "      <td>fiber, flatmap, value, const, maybe</td>\n",
       "      <td>maybe, const, value, flatmap, fiber</td>\n",
       "      <td>[CLS], react, 8, 3, ran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog_20.txt</td>\n",
       "      <td>ai, 최신, 있습니다, ai가, 기술</td>\n",
       "      <td>모델, ai가, 있습니다, 최신, ai</td>\n",
       "      <td>gemini, claude, ##ai, ##2, [CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog_9.txt</td>\n",
       "      <td>상태, const, 업데이트, null, update</td>\n",
       "      <td>update, null, 업데이트, const, 상태</td>\n",
       "      <td>react, [CLS], 19, 19, ##tate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog_8.txt</td>\n",
       "      <td>line, wscellrowi, 엑셀, credit, import</td>\n",
       "      <td>import, subject_name, 엑셀, wscellrowi, line</td>\n",
       "      <td>[CLS], ##com, files, files, https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blog_5.txt</td>\n",
       "      <td>항해, 있습니다, 이런, 프론트엔드, 플러스</td>\n",
       "      <td>프론트엔드, 플러스, 이런, 있습니다, 항해</td>\n",
       "      <td>[CLS], 3, 3, ##ᄀ, 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blog_4.txt</td>\n",
       "      <td>이미지, js, 거야, 쉽게, 이야기</td>\n",
       "      <td>쉽게, 거야, 이야기, js, 이미지</td>\n",
       "      <td>##loading, [CLS], lazy, 3, 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blog_6.txt</td>\n",
       "      <td>typescript, 네이티브, 모든, 것입니다, typescript의</td>\n",
       "      <td>현재, 것입니다, 모든, 네이티브, typescript</td>\n",
       "      <td>faster, 16, [CLS], ##us, ##us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>blog_7.txt</td>\n",
       "      <td>스켈레톤, 로딩, div, ui를, classname</td>\n",
       "      <td>classname, div, ui를, 로딩, 스켈레톤</td>\n",
       "      <td>[CLS], 6, 33, 5, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog_3.txt</td>\n",
       "      <td>것이, 어떻게, 기술, 기업, 내가</td>\n",
       "      <td>하는, 기업, 기술, 어떻게, 것이</td>\n",
       "      <td>[CLS], golden, golden, 7, ##dus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blog_2.txt</td>\n",
       "      <td>user, const, error, userid, data</td>\n",
       "      <td>div, userid, error, const, user</td>\n",
       "      <td>##ssing, ##cek, 41, ##sibility, [CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>blog_1.txt</td>\n",
       "      <td>llm이, 있어요, function, openai, llm</td>\n",
       "      <td>llm, openai, function, 있어요, llm이</td>\n",
       "      <td>agent, ##ai, [CLS], open, ##ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>blog_11.txt</td>\n",
       "      <td>정말, 있습니다, ㅎㅎ, 3월, 그리고</td>\n",
       "      <td>3월, 연구, ㅎㅎ, 있습니다, 정말</td>\n",
       "      <td>offer, associate, offer, [CLS], letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blog_10.txt</td>\n",
       "      <td>내한, 공연, showpot, 티켓팅, 정보를</td>\n",
       "      <td>정보를, 티켓팅, showpot, 공연, 내한</td>\n",
       "      <td>it, [CLS], ##pp, 15, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blog_12.txt</td>\n",
       "      <td>프로젝트, 스몰빅웨딩, 오픈, 이번, 함께</td>\n",
       "      <td>이번, 스몰빅웨딩, 오픈, 함께, 프로젝트</td>\n",
       "      <td>[CLS], ##z, react, api, fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>blog_13.txt</td>\n",
       "      <td>const, console, log, 있다, 함수형</td>\n",
       "      <td>함수형, 있다, console, log, const</td>\n",
       "      <td>cs, [CLS], lee, 6, 58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>blog_17.txt</td>\n",
       "      <td>문서, mdxprovider, 컴포넌트를, components, mdx</td>\n",
       "      <td>mdx, 것이다, mdxprovider, 컴포넌트를, 문서</td>\n",
       "      <td>[CLS], ##ct, react, 10, ##x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>blog_16.txt</td>\n",
       "      <td>text, 대한, 있는, openai, 있습니다</td>\n",
       "      <td>있습니다, openai, 있는, text, 대한</td>\n",
       "      <td>[CLS], agent, calling, ##c, 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>blog_14.txt</td>\n",
       "      <td>자식, 있습니다, const, spawn, data</td>\n",
       "      <td>data, spawn, const, 있습니다, 자식</td>\n",
       "      <td>spawn, 31, ##ode, sonny, [CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>blog_15.txt</td>\n",
       "      <td>func, agent, 있어요, typia, function</td>\n",
       "      <td>직접, typia, agent, 있어요, func</td>\n",
       "      <td>##sons, claude, signature, ##sons, ##sons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            파일명                                   TF-IDF  \\\n",
       "0   blog_18.txt                 답글, 1개의, 그렇기에, 응원합니다, 나는   \n",
       "1   blog_19.txt      fiber, flatmap, value, const, maybe   \n",
       "2   blog_20.txt                    ai, 최신, 있습니다, ai가, 기술   \n",
       "3    blog_9.txt            상태, const, 업데이트, null, update   \n",
       "4    blog_8.txt     line, wscellrowi, 엑셀, credit, import   \n",
       "5    blog_5.txt                 항해, 있습니다, 이런, 프론트엔드, 플러스   \n",
       "6    blog_4.txt                     이미지, js, 거야, 쉽게, 이야기   \n",
       "7    blog_6.txt  typescript, 네이티브, 모든, 것입니다, typescript의   \n",
       "8    blog_7.txt            스켈레톤, 로딩, div, ui를, classname   \n",
       "9    blog_3.txt                      것이, 어떻게, 기술, 기업, 내가   \n",
       "10   blog_2.txt         user, const, error, userid, data   \n",
       "11   blog_1.txt         llm이, 있어요, function, openai, llm   \n",
       "12  blog_11.txt                    정말, 있습니다, ㅎㅎ, 3월, 그리고   \n",
       "13  blog_10.txt                내한, 공연, showpot, 티켓팅, 정보를   \n",
       "14  blog_12.txt                  프로젝트, 스몰빅웨딩, 오픈, 이번, 함께   \n",
       "15  blog_13.txt             const, console, log, 있다, 함수형   \n",
       "16  blog_17.txt  문서, mdxprovider, 컴포넌트를, components, mdx   \n",
       "17  blog_16.txt               text, 대한, 있는, openai, 있습니다   \n",
       "18  blog_14.txt             자식, 있습니다, const, spawn, data   \n",
       "19  blog_15.txt        func, agent, 있어요, typia, function   \n",
       "\n",
       "                                           LDA  \\\n",
       "0                     나는, 응원합니다, 그렇기에, 1개의, 답글   \n",
       "1          maybe, const, value, flatmap, fiber   \n",
       "2                        모델, ai가, 있습니다, 최신, ai   \n",
       "3                update, null, 업데이트, const, 상태   \n",
       "4   import, subject_name, 엑셀, wscellrowi, line   \n",
       "5                     프론트엔드, 플러스, 이런, 있습니다, 항해   \n",
       "6                         쉽게, 거야, 이야기, js, 이미지   \n",
       "7               현재, 것입니다, 모든, 네이티브, typescript   \n",
       "8                classname, div, ui를, 로딩, 스켈레톤   \n",
       "9                          하는, 기업, 기술, 어떻게, 것이   \n",
       "10             div, userid, error, const, user   \n",
       "11            llm, openai, function, 있어요, llm이   \n",
       "12                        3월, 연구, ㅎㅎ, 있습니다, 정말   \n",
       "13                   정보를, 티켓팅, showpot, 공연, 내한   \n",
       "14                     이번, 스몰빅웨딩, 오픈, 함께, 프로젝트   \n",
       "15                함수형, 있다, console, log, const   \n",
       "16            mdx, 것이다, mdxprovider, 컴포넌트를, 문서   \n",
       "17                  있습니다, openai, 있는, text, 대한   \n",
       "18                data, spawn, const, 있습니다, 자식   \n",
       "19                 직접, typia, agent, 있어요, func   \n",
       "\n",
       "                                         BERT  \n",
       "0               squeeze, squeeze, [CLS], 1, 3  \n",
       "1                     [CLS], react, 8, 3, ran  \n",
       "2            gemini, claude, ##ai, ##2, [CLS]  \n",
       "3                react, [CLS], 19, 19, ##tate  \n",
       "4           [CLS], ##com, files, files, https  \n",
       "5                        [CLS], 3, 3, ##ᄀ, 10  \n",
       "6                ##loading, [CLS], lazy, 3, 8  \n",
       "7               faster, 16, [CLS], ##us, ##us  \n",
       "8                          [CLS], 6, 33, 5, 3  \n",
       "9             [CLS], golden, golden, 7, ##dus  \n",
       "10      ##ssing, ##cek, 41, ##sibility, [CLS]  \n",
       "11             agent, ##ai, [CLS], open, ##ge  \n",
       "12     offer, associate, offer, [CLS], letter  \n",
       "13                     it, [CLS], ##pp, 15, 3  \n",
       "14                 [CLS], ##z, react, api, fe  \n",
       "15                      cs, [CLS], lee, 6, 58  \n",
       "16                [CLS], ##ct, react, 10, ##x  \n",
       "17              [CLS], agent, calling, ##c, 3  \n",
       "18             spawn, 31, ##ode, sonny, [CLS]  \n",
       "19  ##sons, claude, signature, ##sons, ##sons  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keyword_extraction_test-fUJ8m5h5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
