import requests
from bs4 import BeautifulSoup
import os
import re
from velog_scraper import VelogScraper 


def fetch_html(url):
    """
    ì£¼ì–´ì§„ URLì—ì„œ HTML ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    """
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        return response.text
    else:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {response.status_code}")
        return None


def extract_main_text(html: str) -> str:
    """
    BeautifulSoupì„ ì‚¬ìš©í•˜ì—¬ HTML ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    """
    soup = BeautifulSoup(html, "lxml")

    # <script>, <style> íƒœê·¸ ì œê±°
    for tag in soup(["script", "style"]):
        tag.decompose()

    # Velog ë³¸ë¬¸ì´ ìˆëŠ” íƒœê·¸ íƒìƒ‰
    content_tag = soup.find("div", class_="markdown-body")
    
    if content_tag:
        main_text = content_tag.get_text(separator=" ", strip=True)
    else:
        main_text = ""

    # ë¶ˆí•„ìš”í•œ ê³µë°± ë° íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    main_text = re.sub(r"[^\w\s]", "", main_text)  # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
    main_text = re.sub(r"\s+", " ", main_text).strip()  # ì¤‘ë³µ ê³µë°± ì œê±°

    return main_text


def process_velog_articles():
    """
    Velog íŠ¸ë Œë”© í˜ì´ì§€ì—ì„œ ëª¨ë“  ë¸”ë¡œê·¸ë¥¼ ê°€ì ¸ì™€ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    """
    # VelogScraperë¥¼ ì´ìš©í•´ íŠ¸ë Œë”© ë¸”ë¡œê·¸ ë§í¬ ê°€ì ¸ì˜¤ê¸°
    scraper = VelogScraper()
    article_links = scraper.get_trending_links()

    if not article_links:
        print("âŒ ë¸”ë¡œê·¸ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"âœ… ì´ {len(article_links)}ê°œì˜ ë¸”ë¡œê·¸ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

    # í´ë” ìƒì„±
    raw_html_dir = "data/raw_html"
    processed_text_dir = "data/processed_text"
    os.makedirs(raw_html_dir, exist_ok=True)
    os.makedirs(processed_text_dir, exist_ok=True)

    for i, link in enumerate(article_links, start=1):
        print(f"ğŸ“Œ {i}/{len(article_links)} ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì¤‘: {link}")
        
        html_content = fetch_html(link)
        if not html_content:
            continue

        # HTML ì €ì¥ (ì›ë³¸ ë°ì´í„° ë³´ê´€)
        raw_html_path = os.path.join(raw_html_dir, f"blog_{i}.html")
        with open(raw_html_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        # ë³¸ë¬¸ ì¶”ì¶œ & ì „ì²˜ë¦¬
        processed_text = extract_main_text(html_content)

        # í…ìŠ¤íŠ¸ ì €ì¥
        processed_text_path = os.path.join(processed_text_dir, f"blog_{i}.txt")
        with open(processed_text_path, "w", encoding="utf-8") as f:
            f.write(processed_text)

        print(f"âœ… ë³¸ë¬¸ ì €ì¥ ì™„ë£Œ: {processed_text_path}")


# ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    process_velog_articles()
